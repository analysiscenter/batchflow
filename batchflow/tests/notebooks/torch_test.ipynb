{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks serves as a demo of `TorchModel` capabilities.\n",
    "\n",
    "Aside from that, it is also used as an interactive test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:39.085332Z",
     "start_time": "2020-02-10T14:48:37.201393Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"../../..\")\n",
    "from batchflow import *\n",
    "from batchflow.opensets import MNIST\n",
    "from batchflow.models.torch import *\n",
    "from batchflow.models.torch.layers import *\n",
    "from batchflow.models.torch.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup: global parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:40.391329Z",
     "start_time": "2020-02-10T14:48:39.087260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "mnist = MNIST(bar=False)\n",
    "\n",
    "BAR = True\n",
    "PLOT = False\n",
    "\n",
    "IMAGE_SHAPE = (1, 28, 28)\n",
    "BATCH_SIZE = 16\n",
    "N_ITERS = 10\n",
    "N_ITERS_LARGE = 100\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MICROBATCH = None\n",
    "    DEVICE = 'gpu:0'\n",
    "    BAR = 't'\n",
    "    PLOT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:40.438798Z",
     "start_time": "2020-02-10T14:48:40.394276Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_classification_config(model_class, config):\n",
    "    default_config = {\n",
    "        # Shapes info. Can be commented\n",
    "        'inputs_shapes': IMAGE_SHAPE,\n",
    "        'classes': 10,\n",
    "\n",
    "        'loss': 'ce',\n",
    "        'microbatch_size': MICROBATCH,\n",
    "        'device': DEVICE,\n",
    "    }\n",
    "\n",
    "    if 'inputs_shapes' in config and isinstance(config['inputs_shapes'], list):\n",
    "        inputs = [B.images for item in config['inputs_shapes']]\n",
    "    else:\n",
    "        inputs = B.images\n",
    "    \n",
    "    \n",
    "    pipeline_config = {\n",
    "        'model': model_class,\n",
    "        'model_config': {**default_config, **config},\n",
    "        'inputs': inputs,\n",
    "        'targets': B.labels,\n",
    "\n",
    "        'gather': {'metrics_class' : 'classification',\n",
    "                   'fmt' : 'logits',\n",
    "                   'axis' : 1,\n",
    "                   'targets' : B.labels},\n",
    "        'evaluate': 'accuracy',\n",
    "    }\n",
    "    return pipeline_config\n",
    "\n",
    "def get_segmentation_config(model_class, config):\n",
    "    default_config = {\n",
    "        # Shapes info. Can be commented\n",
    "        'inputs_shapes': IMAGE_SHAPE,\n",
    "        'targets_shapes': IMAGE_SHAPE,\n",
    "\n",
    "        'loss': 'mse',\n",
    "        'microbatch': MICROBATCH,\n",
    "        'device': DEVICE,\n",
    "    }\n",
    "    \n",
    "    if 'inputs_shapes' in config and isinstance(config['inputs_shapes'], list):\n",
    "        inputs = [B.images for item in config['inputs_shapes']]\n",
    "    else:\n",
    "        inputs = B.images\n",
    "    \n",
    "    pipeline_config = {\n",
    "        'model': model_class,\n",
    "        'model_config': {**default_config, **config},\n",
    "        'inputs': inputs,\n",
    "        'targets': B.images,\n",
    "\n",
    "        'gather': {'metrics_class' : 'segmentation',\n",
    "                   'fmt' : 'proba',\n",
    "                   'axis' : None,\n",
    "                   'targets' : B.images},\n",
    "        'evaluate': 'jaccard',\n",
    "    }\n",
    "    return pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:40.485464Z",
     "start_time": "2020-02-10T14:48:40.440559Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pipeline(pipeline_config):\n",
    "    \"\"\" Pipeline config must contain 'model', 'model_config', 'feed_dict' keys. \"\"\"\n",
    "    pipeline = (Pipeline(config=pipeline_config)\n",
    "                .init_variable('loss_history', [])\n",
    "                .to_array(channels='first', dtype='float32')\n",
    "                .multiply(multiplier=1/255., preserve_type=False)\n",
    "                .init_model(name='MODEL', model_class=C('model'), config=C('model_config'))\n",
    "                .train_model('MODEL',\n",
    "                             inputs=pipeline_config['inputs'],\n",
    "                             targets=pipeline_config['targets'],\n",
    "                             outputs='loss',\n",
    "                             save_to=V('loss_history', mode='a'))\n",
    "                )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:40.517771Z",
     "start_time": "2020-02-10T14:48:40.486919Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(task, model_class, config, description, batch_size=BATCH_SIZE, n_iters=N_ITERS, **kwargs):\n",
    "    if task == 'classification':\n",
    "        pipeline_config = get_classification_config(model_class, config)\n",
    "    elif task == 'segmentation':\n",
    "        pipeline_config = get_segmentation_config(model_class, config)\n",
    "\n",
    "    train_pipeline = get_pipeline(pipeline_config) << mnist.train\n",
    "    _ = train_pipeline.run(batch_size, n_iters=n_iters,\n",
    "                           bar={'bar': BAR, 'monitors': 'loss_history'},\n",
    "                           **kwargs)\n",
    "    \n",
    "    print(f'{task} \"{description}\" is done! Number of parameters in the model: {train_pipeline.model.num_parameters:,}')\n",
    "    return train_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:40.556069Z",
     "start_time": "2020-02-10T14:48:40.520751Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_some_results(ppl, task, size=10):\n",
    "    batch_ind = np.random.randint(len(ppl.v('targets')))\n",
    "    image_ind = np.random.choice(len(ppl.v('targets')[batch_ind]), size=size, replace=False)\n",
    "    true = ppl.v('targets')[batch_ind]\n",
    "    pred = ppl.v('predictions')[batch_ind]\n",
    "\n",
    "    if task == 'classification':\n",
    "        print(pd.DataFrame({'true': true[image_ind],\n",
    "                            'pred': np.argmax(pred[image_ind], axis=1)}).to_string(index=False))\n",
    "    elif task == 'segmentation':\n",
    "        pass # for the sake of parsing by notebooks_test.py\n",
    "        fig, ax = plt.subplots(2, size, figsize=(10, 5))\n",
    "        [axi.set_axis_off() for axi in ax.ravel()]\n",
    "        for plot_num, image_num in enumerate(image_ind):\n",
    "            ax[0][plot_num].imshow(true[image_num][0], cmap='gray', vmin=0, vmax=1)\n",
    "            ax[1][plot_num].imshow(pred[image_num][0], cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:40.598310Z",
     "start_time": "2020-02-10T14:48:40.557588Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(pipeline, show_results=PLOT, batch_size=64, n_epochs=1, drop_last=False):\n",
    "    test_pipeline = (mnist.test.p\n",
    "                    .import_model('MODEL', pipeline)\n",
    "                    .init_variable('targets', default=[])\n",
    "                    .init_variable('predictions', default=[])\n",
    "                    .init_variable('metrics', default=[]) \n",
    "                    .to_array(channels='first', dtype='float32')\n",
    "                    .multiply(multiplier=1/255., preserve_type=False)\n",
    "                    .update(V('targets', mode='a'), pipeline.config['targets'])\n",
    "                    .predict_model('MODEL',\n",
    "                                   inputs=pipeline.config['inputs'],\n",
    "                                   outputs='predictions',\n",
    "                                   save_to=V('predictions', mode='a'))\n",
    "                    .gather_metrics(**pipeline.config['gather'], predictions=V.predictions[-1],\n",
    "                                    save_to=V('metrics', mode='a'))\n",
    "                    .run(batch_size, shuffle=False, n_epochs=n_epochs, drop_last=drop_last, bar=BAR)\n",
    "    )\n",
    "    \n",
    "    if show_results:\n",
    "        show_some_results(test_pipeline, pipeline.config['gather/metrics_class'])\n",
    "\n",
    "    metrics = test_pipeline.get_variable('metrics')\n",
    "    to_evaluate = pipeline.config['evaluate']\n",
    "    evaluated = np.mean([m.evaluate(to_evaluate) for m in metrics])\n",
    "    print(f'{to_evaluate} metrics is: {evaluated:.3}')\n",
    "\n",
    "    return test_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester\n",
    "Test the simplest possible model and record timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {'initial_block': {'layout': 'Vf', 'features': 10}}\n",
    "ppl = run('classification', TorchModel, config, 'simple fc', n_iters=2, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test(ppl, show_results=False, batch_size=BATCH_SIZE, drop_last=True, n_epochs=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:49.391057Z",
     "start_time": "2020-02-10T14:48:40.601257Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'fa'*2,\n",
    "                      'features': [64, 128],},\n",
    "    'body': {'layout': 'fa'*2,\n",
    "             'features': [256, 512]},\n",
    "    'head': {'layout': 'faf',\n",
    "             'features': [600, 10]},\n",
    "}\n",
    "\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'simple fc', n_iters=200, batch_size=64)\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T12:36:22.116738Z",
     "start_time": "2020-02-14T12:36:21.721466Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'body': {'type': 'encoder',\n",
    "             'output_type': 'tensor',\n",
    "             'num_stages': 3,\n",
    "             'blocks/channels': '2 * same'},\n",
    "    'head': {'layout': 'f'}\n",
    "}\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:50.496333Z",
     "start_time": "2020-02-10T14:48:50.091585Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example with multiple inputs\n",
    "config = {\n",
    "    'inputs_shapes': [IMAGE_SHAPE, IMAGE_SHAPE],\n",
    "\n",
    "    'initial_block': {'type': 'wrapper',\n",
    "                      'input_type': 'list',\n",
    "                      'input_index': slice(None),\n",
    "                      'module': Combine(op='concat', force_resize=False),},\n",
    "    'body': {'type': 'encoder',\n",
    "             'num_stages': 3,\n",
    "             'output_type': 'tensor',\n",
    "             'blocks/channels': '2 * same'},\n",
    "    'head': {'layout': 'faf', 'features': [50, 10]}\n",
    "}\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'duo input')\n",
    "ppl.model.repr(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: named networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl = run('classification', VGG16, {}, 'vgg16', n_iters=100, batch_size=128)\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T12:36:33.046337Z",
     "start_time": "2020-02-14T12:36:26.373349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl = run('classification', ResNet18, {}, 'resnet18', n_iters=100, batch_size=128)\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T12:36:33.046337Z",
     "start_time": "2020-02-14T12:36:26.373349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl = run('classification', SEResNeXt18, {}, 'SE-ResNeXt18', n_iters=100, batch_size=128)\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl = run('classification', DenseNetS, {}, 'DenseNetS', n_iters=100, batch_size=128)\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl = run('classification', EfficientNetB0, {}, 'EfficientNetB0', n_iters=100, batch_size=128)\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'cna', 'channels': 3,\n",
    "                      'kernel_size': 5, 'stride': 1, 'padding': 'same'},\n",
    "    'body': {'num_stages': 4,\n",
    "             'blocks': {'n_reps': [1, 1, 2, 1],\n",
    "                        'channels': '2 * same',\n",
    "                        'attention': 'se'}\n",
    "            }\n",
    "}\n",
    "\n",
    "ppl = run('classification', ResNet, config, 'resnet with config', n_iters=50, batch_size=128)\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:07.166937Z",
     "start_time": "2020-02-10T14:49:03.721908Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reusing encoder from model from the previous cell\n",
    "config = {\n",
    "    'initial_block': {'type': 'wrapper', 'module': ppl.model.model.initial_block},\n",
    "    'body': {'type': 'wrapper', 'module': ppl.model.model.body},\n",
    "    'head' : {'type': 'wrapper', 'module': ppl.model.model.head},\n",
    "}\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'reused encoder', n_iters=50, batch_size=32)\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classification: imported models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:13.071000Z",
     "start_time": "2020-02-10T14:49:07.169608Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18.fc = torch.nn.Identity()\n",
    "\n",
    "config = {\n",
    "    'initial_block': {'layout': 'cna',\n",
    "                      'channels': 3},\n",
    "    'body': {'type': 'wrapper', 'module': resnet18},\n",
    "    'head': {'layout': 'Dnfaf',\n",
    "             'features': [50, 10],\n",
    "             'dropout_rate': 0.3,\n",
    "             'multisample': 0.3},\n",
    "}\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'torchvision resnet', n_iters=100, batch_size=128)\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {\n",
    "        'layout': 'cna',\n",
    "        'channels': 3,\n",
    "        'output_list': True\n",
    "    },\n",
    "    'body': {\n",
    "        'type': 'timm',\n",
    "        'output_type': 'tensor',\n",
    "        'path': 'resnet34d',\n",
    "        'pretrained': True,\n",
    "    },\n",
    "    'head': {'layout': 'Dnfaf',\n",
    "             'features': [50, 10],\n",
    "             'dropout_rate': 0.3,\n",
    "             'multisample': 0.3},\n",
    "}\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'TIMM-resnet34', n_iters=100, batch_size=128)\n",
    "# ppl.model.model.body.config\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'trainable': ['initial_block', 'head'],\n",
    "    **config\n",
    "}\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'TIMM-resnet34 finetune', n_iters=100, batch_size=128)\n",
    "# ppl.model.model.body.config\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {\n",
    "        'layout': 'cna',\n",
    "        'channels': 3,\n",
    "        'output_list': True\n",
    "    },\n",
    "    'body': {\n",
    "        'type': 'hugging-face',\n",
    "        'output_type': 'tensor',\n",
    "        'path': 'facebook/convnext-tiny-224',\n",
    "        'num_stages': 2,\n",
    "        'depths': [2, 2],\n",
    "        'num_channels': 3,        # number of input channels\n",
    "        'patch_size': 2,          # ~stride in the beginning\n",
    "        'hidden_sizes': [48, 64], # ~channels\n",
    "    },\n",
    "    'head': {'layout': 'Dnfaf',\n",
    "             'features': [50, 10],\n",
    "             'dropout_rate': 0.3,\n",
    "             'multisample': 0.3},\n",
    "}\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'HF-ConvNext', n_iters=100, batch_size=128)\n",
    "# ppl.model.model.body.config\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {\n",
    "        'layout': 'cna',\n",
    "        'channels': 3,\n",
    "        'output_list': True\n",
    "    },\n",
    "    'body': {\n",
    "        'type': 'hugging-face',\n",
    "        'output_type': 'tensor',\n",
    "        'path': 'nvidia/segformer-b0-finetuned-ade-512-512',\n",
    "        'num_encoder_blocks': 2,                              # ~num_stages\n",
    "        'strides': [2, 2],\n",
    "        'num_attention_heads': [1, 4],\n",
    "        'hidden_sizes': [48, 64],                             # ~channels\n",
    "    },\n",
    "    'head': {'layout': 'Dnfaf',\n",
    "             'features': [50, 10],\n",
    "             'dropout_rate': 0.3,\n",
    "             'multisample': 0.3},\n",
    "}\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'HF-SegFormer', n_iters=100, batch_size=128)\n",
    "# ppl.model.model.body.config\n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl.model.repr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:13.696338Z",
     "start_time": "2020-02-10T14:49:13.081798Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'cna', 'channels': 1},\n",
    "    'body': {'type': 'decoder',\n",
    "             'num_stages': 3,\n",
    "             'order': ['block'],}\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', TorchModel, config, 'decoder')\n",
    "ppl.model.repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:44.607432Z",
     "start_time": "2020-02-10T14:49:43.604775Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {\n",
    "        'layout': 'cnaRp cnaRp tna+ tna+ BScna+ cnac',\n",
    "        'channels': [16, 32, 32, 16, 'same', 8, 1],\n",
    "        'custom_padding': False,\n",
    "        'transposed_conv': {'kernel_size': 2, 'stride': 2},\n",
    "        'branch': {'layout': 'ca', 'channels': 'same'}\n",
    "    },\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', TorchModel, config, 'hardcoded unet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:48.472236Z",
     "start_time": "2020-02-10T14:49:47.070986Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'order': ['initial_block', 'encoder', 'embedding', 'decoder', 'head'],\n",
    "    \n",
    "    'initial_block': {\n",
    "        'layout': 'cna',\n",
    "        'channels': 8\n",
    "    },\n",
    "    'encoder': {\n",
    "        'type': 'encoder',\n",
    "        'num_stages': 3,\n",
    "        'blocks/channels': '2 * same',\n",
    "        'skip': {'channels': 'int(1.2 * same)', 'layout': 'cna'}\n",
    "    },\n",
    "    'embedding': {\n",
    "        'layout': 'cna',\n",
    "        'channels': 'same', \n",
    "        'input_type': 'list',\n",
    "        'output_type': 'list',\n",
    "    },\n",
    "    'decoder': {\n",
    "        'type': 'decoder',\n",
    "        'blocks/channels': 'same // 2',\n",
    "        'upsample': {'layout': 'b', 'factor': 2},\n",
    "    },\n",
    "    'head': {\n",
    "        'layout': 'c', \n",
    "        'channels': 1}\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', TorchModel, config, 'encoder->embedding->decoder from scratch')\n",
    "ppl.model.model.repr(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:46.448465Z",
     "start_time": "2020-02-10T14:49:45.798839Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'order': ['initial_block', 'encoder', 'embedding', 'decoder', 'head'],\n",
    "    \n",
    "    'encoder': {\n",
    "        'type': 'encoder',\n",
    "        'num_stages': 2,\n",
    "        'blocks/channels': '4 * same'\n",
    "    },\n",
    "    'embedding': {\n",
    "        'base_block': ASPP,\n",
    "        'channels': 4,\n",
    "        'pyramid': (2, 4, 8), \n",
    "        'input_type': 'list',\n",
    "        'output_type': 'list',\n",
    "    },\n",
    "    'decoder': {\n",
    "        'type': 'decoder',\n",
    "        'num_stages': 2,\n",
    "        'blocks': {'base_block': ResBlock, 'channels': 'same'},\n",
    "        'upsample': {'layout': 'b', 'factor': 2}\n",
    "    },\n",
    "    'head': {\n",
    "        'layout': 'c',\n",
    "        'channels': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', TorchModel, config, 'unet-like with ASPP', n_iters=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation: named networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:48.472236Z",
     "start_time": "2020-02-10T14:49:47.070986Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'cna', 'channels': 4},\n",
    "    'encoder': {'blocks/channels': 'int(same * 1.3)'},\n",
    "    'embedding': {'channels': 'same'},\n",
    "    'decoder': {'blocks/channels': 'int(same // 1.3)',\n",
    "                'upsample': {'layout': 'b', 'factor': 2}},\n",
    "    'head': {'layout': 'c', 'channels': 1}\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', UNet, config, 'unet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:48.472236Z",
     "start_time": "2020-02-10T14:49:47.070986Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl = run('segmentation', ResUNet, config, 'unet with residual blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:52.971834Z",
     "start_time": "2020-02-10T14:49:49.071501Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'cna', 'channels': 4},\n",
    "    'encoder/num_stages': 2,\n",
    "    'embedding/channels': 6,\n",
    "    'decoder/blocks/channels': 6,\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', DenseUNet, config, 'unet with dense blocks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation: imported encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'order': ['initial_block', 'encoder', 'decoder', 'head'],\n",
    "    \n",
    "    'initial_block': {\n",
    "        'layout': 'cna',\n",
    "        'channels': 3,\n",
    "        'output_type': 'list',\n",
    "    },\n",
    "    'encoder': {\n",
    "        'type': 'hugging-face',\n",
    "        'path': 'nvidia/segformer-b0-finetuned-ade-512-512',\n",
    "        'num_encoder_blocks': 2,                              # ~num_stages\n",
    "        'strides': [2, 2],\n",
    "        'num_attention_heads': [1, 4],\n",
    "        'hidden_sizes': [48, 64],                             # ~channels\n",
    "    },\n",
    "    'decoder': {\n",
    "        'type': 'mlpdecoder',\n",
    "        'upsample/features': 16,\n",
    "        'block/channels': 16,\n",
    "    },\n",
    "\n",
    "    'head': {'layout': 'c',\n",
    "             'channels': 1},\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', TorchModel, config, 'HF-SegFormer + mlp-decoder', n_iters=100, batch_size=128)\n",
    "ppl.model.repr(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl.model.model.repr(2, show_num_parameters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'order': ['initial_block', 'encoder', 'embedding', 'decoder', 'head'],\n",
    "    \n",
    "    'initial_block': {\n",
    "        'layout': 'cna',\n",
    "        'channels': 3,\n",
    "        'output_type': 'list',\n",
    "    },\n",
    "    'encoder': {\n",
    "        'type': 'timm',\n",
    "        'path': 'resnet18',\n",
    "        'pretrained': True,\n",
    "        'out_indices': (0, 1, 2),\n",
    "    },\n",
    "    'embedding': {\n",
    "        'base_block': ResBlock,\n",
    "        'channels': 'same',\n",
    "        'input_type': 'list',\n",
    "        'output_type': 'list',\n",
    "    },\n",
    "    'decoder': {\n",
    "        'type': 'decoder',\n",
    "        'num_stages': 3,\n",
    "        'blocks': {'base_block': ResBlock, 'channels': 'same // 4'},\n",
    "        'upsample': {'layout': 'b', 'factor': 2},\n",
    "    },\n",
    "\n",
    "    'head': {'layout': 'c',\n",
    "             'channels': 1},\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', TorchModel, config, 'TIMM-ResNet18 + decoder', n_iters=100, batch_size=128)\n",
    "ppl.model.repr(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl.model.model.repr(2, show_num_parameters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'callbacks': [\n",
    "    ReduceLROnPlateau(patience=20, cooldown=20, min_delta=0.1, factor=0.9),\n",
    "    EarlyStopping(patience=100, min_delta=0.01)\n",
    "    ],\n",
    "    'decay': {'name': 'exp', 'gamma': 0.8, 'frequency': 20},\n",
    "}\n",
    "\n",
    "with Monitor() as monitor:\n",
    "    ppl = run('classification', ResNet34, config, 'resnet34', batch_size=64, n_iters=200)\n",
    "    \n",
    "test(ppl, show_results=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl.model.show_loss()\n",
    "# ppl.model.show_lr() # only learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "monitor.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T12:41:11.908921Z",
     "start_time": "2020-02-14T12:41:11.875720Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl.model.information()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'amp': False,\n",
    "}\n",
    "\n",
    "ppl = run('classification', ResNet34, config, 'resnet34', batch_size=64, n_iters=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'amp': True # default\n",
    "}\n",
    "\n",
    "ppl = run('classification', ResNet34, config, 'resnet34', batch_size=64, n_iters=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'amp': True,\n",
    "    'sam_rho': 0.05,\n",
    "}\n",
    "\n",
    "ppl = run('classification', ResNet34, config, 'resnet34', batch_size=64, n_iters=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wrappers: TTA + augmentations on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "config = {\n",
    "    'order': ['aug0', 'preprocess', 'initial_block', 'body', 'head'],\n",
    "    \n",
    "    'aug0': {\n",
    "        'module': transforms.Compose([\n",
    "            # transforms.RandomAdjustSharpness(0.1, p=1.0),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "        ]),\n",
    "        'disable_at_inference': True,\n",
    "    },\n",
    "    'preprocess': {\n",
    "        'module': transforms.Resize(32),\n",
    "        'disable_at_inference': False,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "ppl = run('classification', ResNet18, config, 'resnet18', n_iters=100, batch_size=128)\n",
    "print(f'Used modules at train: {ppl.model.model._last_used_modules}')\n",
    "\n",
    "test(ppl, show_results=False)\n",
    "print(f'Used modules at inference: {ppl.model.model._last_used_modules}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl.model.repr(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ttach\n",
    "ppl.model.wrap_tta(wrapper='ClassificationTTAWrapper',\n",
    "                   transforms=ttach.aliases.vlip_transform(),\n",
    "                   merge_mode='mean')\n",
    "\n",
    "test(ppl, show_results=False)\n",
    "print(f'Used modules at inference: {ppl.model.model.model._last_used_modules}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrappers: TRT demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl = run('classification', ResNet34, {}, 'resnet34', batch_size=64, n_iters=200)\n",
    "test(ppl, show_results=False, batch_size=BATCH_SIZE);\n",
    "\n",
    "model = ppl.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from torch2trt import torch2trt\n",
    "\n",
    "module = model.model.eval()\n",
    "inputs = model.make_placeholder_data(batch_size=BATCH_SIZE, unwrap=False)\n",
    "\n",
    "model_trt = torch2trt(module=module.eval(), inputs=inputs,\n",
    "                      fp16_mode=True, use_onnx=True, max_batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = torch.abs(model_trt(*inputs) - module.eval()(*inputs))\n",
    "torch.max(diff), torch.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -r 20 -n 100\n",
    "inputs = model.make_placeholder_data(batch_size=BATCH_SIZE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = module.eval()(inputs).cpu()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "del output, inputs\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -r 20 -n 100\n",
    "inputs = model.make_placeholder_data(batch_size=BATCH_SIZE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model_trt(inputs).cpu()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "del output, inputs\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrappers: TRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.wrap_trt(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -r 20 -n 100\n",
    "inputs = model.make_placeholder_data(batch_size=BATCH_SIZE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.model(inputs).cpu()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "del output, inputs\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = model.make_placeholder_data(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.model(torch.tile(inputs, (BATCH_SIZE, 1, 1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test(ppl, show_results=False, batch_size=BATCH_SIZE, drop_last=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrappers: TTA + TRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppl = run('classification', ResNet34, {}, 'resnet34', batch_size=BATCH_SIZE, n_iters=200)\n",
    "\n",
    "model = ppl.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test(ppl, show_results=False, batch_size=BATCH_SIZE, drop_last=True, n_epochs=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.wrap_trt(batch_size=BATCH_SIZE, fp16_mode=True)\n",
    "\n",
    "# import ttach\n",
    "# ppl.model.wrap_tta(wrapper='ClassificationTTAWrapper',\n",
    "#                    transforms=ttach.aliases.vlip_transform(),\n",
    "#                    merge_mode='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test(ppl, show_results=False, batch_size=BATCH_SIZE, drop_last=True, n_epochs=5);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
