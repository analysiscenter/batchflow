{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:39.085332Z",
     "start_time": "2020-02-10T14:48:37.201393Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "sys.path.append(\"../../..\")\n",
    "from batchflow import *\n",
    "from batchflow.opensets import MNIST\n",
    "from batchflow.models.torch import *\n",
    "from batchflow.models.torch.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:40.391329Z",
     "start_time": "2020-02-10T14:48:39.087260Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist = MNIST()\n",
    "\n",
    "BAR = True\n",
    "PLOT = False\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MICROBATCH = None\n",
    "    DEVICE = None\n",
    "    BAR = 'n'\n",
    "    PLOT = True\n",
    "\n",
    "print('\\nMicrobatching is: {}'.format(MICROBATCH))\n",
    "print('\\nDevice is: {}'.format(DEVICE))\n",
    "print('\\nBar style is: {}'.format(BAR))\n",
    "print('\\nPlot results is: {}'.format(PLOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:40.438798Z",
     "start_time": "2020-02-10T14:48:40.394276Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (1, 28, 28)\n",
    "N_ITERS = 10\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def get_classification_config(model_class, config):\n",
    "    default_config = {\n",
    "        'inputs/images/shape': IMAGE_SHAPE, # can be commented\n",
    "        'inputs/labels/classes': 10,\n",
    "        'initial_block/inputs': 'images',   # can be commented\n",
    "        'loss': 'ce',\n",
    "        'microbatch': MICROBATCH,\n",
    "        'device': DEVICE,\n",
    "    }\n",
    "\n",
    "    pipeline_config = {\n",
    "        'model': model_class,\n",
    "        'model_config': {**default_config, **config},\n",
    "        'feed_dict': {'images': B('images'),\n",
    "                      'targets': B('labels')},\n",
    "        'gather': {'metrics_class' : 'classification',\n",
    "                   'fmt' : 'logits',\n",
    "                   'axis' : 1,\n",
    "                   'targets' : B.labels},\n",
    "        'evaluate': 'accuracy',\n",
    "    }\n",
    "    return pipeline_config\n",
    "\n",
    "def get_segmentation_config(model_class, config):\n",
    "    default_config = {\n",
    "        'inputs/images/shape': IMAGE_SHAPE, # can be commented\n",
    "        'inputs/masks/shape': IMAGE_SHAPE,  # can be commented\n",
    "        'initial_block/inputs': 'images',   # can be commented\n",
    "        'loss': 'mse',\n",
    "        'microbatch': MICROBATCH,\n",
    "        'device': DEVICE,\n",
    "    }\n",
    "    \n",
    "    pipeline_config = {\n",
    "        'model': model_class,\n",
    "        'model_config': {**default_config, **config},\n",
    "        'feed_dict': {'images': B('images'),\n",
    "                      'targets': B('images')},\n",
    "        'gather': {'metrics_class' : 'segmentation',\n",
    "                   'fmt' : 'proba',\n",
    "                   'axis' : None,\n",
    "                   'targets' : B.images},\n",
    "        'evaluate': 'jaccard',\n",
    "    }\n",
    "    return pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:40.485464Z",
     "start_time": "2020-02-10T14:48:40.440559Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pipeline(pipeline_config):\n",
    "    \"\"\" Pipeline config must contain 'model', 'model_config', 'feed_dict' keys. \"\"\"\n",
    "    vals = pipeline_config['feed_dict'].values()\n",
    "\n",
    "    pipeline = (Pipeline(config=pipeline_config)\n",
    "                .init_variable('loss_history', [])\n",
    "                .to_array(channels='first', dtype='float32')\n",
    "                .multiply(multiplier=1/255., preserve_type=False)\n",
    "                .init_model('dynamic', C('model'),\n",
    "                            'MODEL', config=C('model_config'))\n",
    "                .train_model('MODEL',\n",
    "#                              *vals,\n",
    "#                              feed_dict=C('feed_dict'),\n",
    "                             **pipeline_config['feed_dict'],\n",
    "                             fetches='loss',\n",
    "                             save_to=V('loss_history', mode='a'))\n",
    "                )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:40.517771Z",
     "start_time": "2020-02-10T14:48:40.486919Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(task, model_class, config, description, batch_size=BATCH_SIZE, n_iters=N_ITERS):\n",
    "    if task == 'classification':\n",
    "        pipeline_config = get_classification_config(model_class, config)\n",
    "    elif task == 'segmentation':\n",
    "        pipeline_config = get_segmentation_config(model_class, config)\n",
    "\n",
    "    train_pipeline = get_pipeline(pipeline_config) << mnist.train\n",
    "    _ = train_pipeline.run(batch_size, n_iters=n_iters, bar=BAR,\n",
    "                           bar_desc=W(V('loss_history')[-1].format('Loss is {:7.7}')))\n",
    "    \n",
    "    print('{} {} is done'.format(task, description))\n",
    "    return train_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:40.556069Z",
     "start_time": "2020-02-10T14:48:40.520751Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_some_results(ppl, task, size=10):\n",
    "    batch_ind = np.random.randint(len(ppl.v('targets')))\n",
    "    image_ind = np.random.choice(len(ppl.v('targets')[batch_ind]), size=size, replace=False)\n",
    "    true = ppl.v('targets')[batch_ind]\n",
    "    pred = ppl.v('predictions')[batch_ind]\n",
    "\n",
    "    if task == 'classification':\n",
    "        print(pd.DataFrame({'true': true[image_ind],\n",
    "                            'pred': np.argmax(pred[image_ind], axis=1)}).to_string(index=False))\n",
    "    elif task == 'segmentation':\n",
    "        pass # for the sake of parsing by notebooks_test.py\n",
    "        fig, ax = plt.subplots(2, size, figsize=(10, 5))\n",
    "        [axi.set_axis_off() for axi in ax.ravel()]\n",
    "        for plot_num, image_num in enumerate(image_ind):\n",
    "            ax[0][plot_num].imshow(true[image_num][0], cmap='gray', vmin=0, vmax=1)\n",
    "            ax[1][plot_num].imshow(pred[image_num][0], cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:40.598310Z",
     "start_time": "2020-02-10T14:48:40.557588Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(pipeline, show_results=PLOT):\n",
    "    test_pipeline = (mnist.test.p\n",
    "                    .import_model('MODEL', pipeline)\n",
    "                    .init_variable('targets', default=[])\n",
    "                    .init_variable('predictions', default=[])\n",
    "                    .init_variable('metrics', default=[]) \n",
    "                    .to_array(channels='first', dtype='float32')\n",
    "                    .multiply(multiplier=1/255., preserve_type=False)\n",
    "                    .update(V('targets', mode='a'), pipeline.config['feed_dict/targets'])\n",
    "                    .predict_model('MODEL',\n",
    "#                                    targets=B.images,\n",
    "                                   feed_dict=pipeline.config['feed_dict'],\n",
    "                                   fetches='predictions',\n",
    "                                   save_to=V('predictions', mode='a'))\n",
    "                    .gather_metrics(**pipeline.config['gather'], predictions=V.predictions[-1],\n",
    "                                    save_to=V('metrics', mode='a'))\n",
    "                    .run(64, shuffle=False, n_epochs=1, drop_last=False, bar=BAR)\n",
    "    )\n",
    "    \n",
    "    if show_results:\n",
    "        show_some_results(test_pipeline, pipeline.config['gather/metrics_class'])\n",
    "\n",
    "    metrics = test_pipeline.get_variable('metrics')\n",
    "    to_evaluate = pipeline.config['evaluate']\n",
    "    evaluated = np.mean([m.evaluate(to_evaluate) for m in metrics])\n",
    "    print('{0} metrics is: {1:.3}'.format(to_evaluate, evaluated))\n",
    "\n",
    "    return test_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:49.391057Z",
     "start_time": "2020-02-10T14:48:40.601257Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'fa'*2,\n",
    "                      'units': [64, 128],},\n",
    "    'body': {'layout': 'fa'*2,\n",
    "             'units': [256, 512]},\n",
    "    'head': {'layout': 'faf',\n",
    "             'units': [600, 10]},\n",
    "}\n",
    "\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'simple fc', n_iters=50, batch_size=64)\n",
    "# test(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T12:36:22.116738Z",
     "start_time": "2020-02-14T12:36:21.721466Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'body/encoder/num_stages': 5,\n",
    "    'head': {'layout': 'f'}\n",
    "}\n",
    "\n",
    "ppl = run('classification', Encoder, config, 'encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:50.090131Z",
     "start_time": "2020-02-10T14:48:49.763142Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'fafaf', 'units': [128, 256, 10]},\n",
    "    'order': ['initial_block', ('ib_2', 'initial_block', TorchModel.initial_block)],\n",
    "    'loss': ['ce', 'ce'],\n",
    "    'decay': 'exp',\n",
    "    'n_iters': 25,\n",
    "    'train_steps': {'ts_1': {}, 'ts_2': {}},\n",
    "}\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'train steps and order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:48:50.496333Z",
     "start_time": "2020-02-10T14:48:50.091585Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block/inputs': ['images', 'images'],\n",
    "    # note that we can't directly assign this module to `initial_block`\n",
    "    'initial_block/module': Combine(op='+'),\n",
    "    'body/encoder': {'num_stages': 5},\n",
    "    'head': {'layout': 'faf', 'units': [50, 10]}\n",
    "}\n",
    "\n",
    "ppl = run('classification', Encoder, config, 'duo input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T12:41:40.763896Z",
     "start_time": "2020-02-14T12:41:37.322622Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block/filters': 6,\n",
    "    'body/encoder/blocks/n_reps': [1, 1, 2, 1],\n",
    "    'body/encoder/blocks/bottleneck': False,\n",
    "    'body/encoder/blocks/attention': 'se',\n",
    "}\n",
    "\n",
    "ppl = run('classification', ResNet, config, 'resnet with config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T12:41:43.661416Z",
     "start_time": "2020-02-14T12:41:43.591313Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppl.m('MODEL').info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T12:36:33.046337Z",
     "start_time": "2020-02-14T12:36:26.373349Z"
    }
   },
   "outputs": [],
   "source": [
    "ppl = run('classification', ResNet18, {}, 'resnet18')\n",
    "ppl = run('classification', SEResNeXt18, {}, 'SE-resneXt18')\n",
    "# ppl = run('classification', DenseNet121, {}, 'DenseNet121')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:03.632479Z",
     "start_time": "2020-02-10T14:49:00.150428Z"
    }
   },
   "outputs": [],
   "source": [
    "ppl = run('classification', VGG7, {}, 'vgg7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:07.166937Z",
     "start_time": "2020-02-10T14:49:03.721908Z"
    }
   },
   "outputs": [],
   "source": [
    "# reusing encoder from model from the previous cell\n",
    "config = {\n",
    "    'initial_block': ppl.m('MODEL').model.body.encoder,\n",
    "    'head' : {'layout': 'Vf'},\n",
    "}\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'reused encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:13.071000Z",
     "start_time": "2020-02-10T14:49:07.169608Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18.fc = torch.nn.Identity()\n",
    "\n",
    "config = {\n",
    "    'initial_block': {'layout': 'cna',\n",
    "                      'filters': 3},\n",
    "    'body': resnet18,\n",
    "    'head': {'layout': 'Dnfaf',\n",
    "             'units': [50, 10],\n",
    "             'dropout_rate': 0.3,\n",
    "             'multisample': 0.3},\n",
    "}\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'pretrained resnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:13.696338Z",
     "start_time": "2020-02-10T14:49:13.081798Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'cna', 'filters': 8},\n",
    "    'body/decoder/num_stages': 3,\n",
    "    'body/decoder/factor': [1, 1, 1],\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', Decoder, config, 'decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:44.607432Z",
     "start_time": "2020-02-10T14:49:43.604775Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'step_on_each': 1,\n",
    "    'initial_block': {\n",
    "        'layout': 'cnaRp cnaRp tna+ tna+ BScna+ cnac',\n",
    "        'filters': [16, 32, 32, 16, 'same', 8, 1],\n",
    "        'transposed_conv': {'kernel_size': 2, 'strides': 2},\n",
    "        'branch': {'layout': 'ca', 'filters': 'same'}\n",
    "    },\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', TorchModel, config, 'hardcoded unet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:46.448465Z",
     "start_time": "2020-02-10T14:49:45.798839Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'body/encoder/num_stages': 2,\n",
    "    'body/embedding': {'base': ASPP, 'pyramid': (2, 4, 8)},\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', EncoderDecoder, config, 'unet-like with ASPP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:48.472236Z",
     "start_time": "2020-02-10T14:49:47.070986Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block/filters': 128,\n",
    "    'body/encoder/num_stages': 3,\n",
    "    'body/encoder/blocks/filters': 'same*2',\n",
    "    'body/embedding/filters': 'same',\n",
    "    'body/decoder/blocks/filters': 'same//2',\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', UNet, config, 'unet')\n",
    "# ppl = run('segmentation', ResUNet, config, 'unet with residual blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:52.971834Z",
     "start_time": "2020-02-10T14:49:49.071501Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block/filters': 16,\n",
    "    'body/encoder/num_stages': 2,\n",
    "    'body/embedding/filters': 6,\n",
    "    'body/decoder/blocks/filters': 6,\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', DenseUNet, config, 'unet with dense blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T14:49:55.529346Z",
     "start_time": "2020-02-10T14:49:53.953549Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'body/encoder/base_model': ResNet18,\n",
    "    'body/encoder/base_model_kwargs/blocks/filters': 7, \n",
    "    'body/decoder/blocks/filters': 'same//4'\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', EncoderDecoder, config, 'encoder-decoder with resnet18 backbone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T12:41:11.908921Z",
     "start_time": "2020-02-14T12:41:11.875720Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppl.m('MODEL').info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T12:36:52.505206Z",
     "start_time": "2020-02-14T12:36:52.447265Z"
    }
   },
   "outputs": [],
   "source": [
    "# ppl.m('MODEL').set_debug_mode(True)\n",
    "ppl.m('MODEL').model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
